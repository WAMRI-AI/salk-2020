{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.learner import cnn_config\n",
    "from fastai.callbacks import *\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../model')\n",
    "from model.losses import *\n",
    "from model.bpho.resnet import *\n",
    "from model.bpho.unet import *\n",
    "from model.metrics import psnr, ssim\n",
    "from data.load_fluo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 3\n",
    "num_cores = 4\n",
    "torch.cuda.set_device(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapting feature loss to wnresnet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_pth = Path('/home/alaa/Dropbox/BPHO Staff/USF/Mitotracker/models')\n",
    "critic_sf = load_learner(path=critic_pth/'baselines',file='mitotracker_PSSR-SF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = critic_sf.model.model[0].eval()\n",
    "flattened_encoder = flatten_model(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{torch.nn.modules.activation.ReLU,\n",
       " torch.nn.modules.conv.Conv2d,\n",
       " torch.nn.modules.pooling.AdaptiveAvgPool2d,\n",
       " torch.nn.modules.pooling.AvgPool2d,\n",
       " torch.nn.modules.pooling.MaxPool2d}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the types of layers to find grid-changing layers\n",
    "layer_types = {type(layer) for layer in flattened_encoder}; layer_types\n",
    "# grid-changing layers include:\n",
    "# 1. conv2d with stride=2\n",
    "# 2. all pooling layers\n",
    "# add controls in find_layers() function to find these layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_model(model):\n",
    "    \"\"\"Using children() method, flatten a complex model.\"\"\"\n",
    "    flattened = []\n",
    "\n",
    "    def get_children(block):\n",
    "        for child in list(block.children()):\n",
    "            grand_children = list(child.children())\n",
    "            if len(grand_children):\n",
    "                get_children(child)\n",
    "            else: flattened.append(child)\n",
    "    \n",
    "    get_children(model)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_layers(flattened_model):\n",
    "    \"\"\"Find the layers previous to the grid-changing layers in a flattened model.\"\"\"\n",
    "    \n",
    "    def is_grid_changing(layer):\n",
    "        \"\"\"add controls here\"\"\"\n",
    "        if 'pooling' in str(type(layer)): return True\n",
    "        if isinstance(layer, torch.nn.modules.conv.Conv2d) and layer.stride==(2,2):\n",
    "            return True\n",
    "    \n",
    "    loss_features = []\n",
    "    for i, layer in enumerate(flattened_model[1:]):\n",
    "        if is_grid_changing(layer):\n",
    "            loss_features.append(flattened_model[i]) \n",
    "            # append the layer previous to the grid-changing ones\n",
    "            # want to see the grid-changing ones? add the index by 1\n",
    "            # loss_features.append(flattened_model[i+1]) \n",
    "    return loss_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.__name__ = 'feat_loss'\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = find_layers(flatten_model(self.m_feat))\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [\n",
    "            f'feat_{i}' for i in range(len(self.loss_features))\n",
    "              ] + [f'gram_{i}' for i in range(len(self.loss_features))]\n",
    "    \n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(pred)\n",
    "        self.feat_losses = [base_loss(pred,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "\n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate feature loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = critic_sf.model.model[0].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how many feature maps are in the feature loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = find_layers(flatten_model(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  tweak layer_wgts accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(m_feat=encoder, layer_wgts=[1/8 for _ in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training with feature loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = wnres_unet_learner(data, arch, in_c=n_frames, wnres_args=wnres_args,\n",
    "                           loss_func=feat_loss, \n",
    "                           metrics=metrics, model_dir=model_pth, callback_fns=[LossMetrics], wd=wd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Salk)",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
