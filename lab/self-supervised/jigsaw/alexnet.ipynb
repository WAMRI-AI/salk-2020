{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "import torch.nn.init as init\n",
    "\n",
    "from pathlib import Path\n",
    "data_pth = Path('/home/alaa/Dropbox/BPHO Staff/USF/EM/training/trainsets/hr/')\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(list(data_pth.glob('*.tif'))[0]).convert('L')\n",
    "from JigsawNetwork import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_size=150, classes=24):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module('conv1_s1',nn.Conv2d(1, 96, kernel_size=11, stride=2, padding=0))\n",
    "        self.conv.add_module('relu1_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool1_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.conv.add_module('lrn1_s1',LRN(local_size=5, alpha=0.0001, beta=0.75))\n",
    "\n",
    "        self.conv.add_module('conv2_s1',nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2))\n",
    "        self.conv.add_module('relu2_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool2_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.conv.add_module('lrn2_s1',LRN(local_size=5, alpha=0.0001, beta=0.75))\n",
    "\n",
    "        self.conv.add_module('conv3_s1',nn.Conv2d(256, 384, kernel_size=3, padding=1))\n",
    "        self.conv.add_module('relu3_s1',nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv.add_module('conv4_s1',nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2))\n",
    "        self.conv.add_module('relu4_s1',nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv.add_module('conv5_s1',nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2))\n",
    "        self.conv.add_module('relu5_s1',nn.ReLU(inplace=True))\n",
    "        self.conv.add_module('pool5_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        test_tensor = torch.ones([1, 1, patch_size, patch_size])\n",
    "        output_size = self.conv(test_tensor).shape[-1]**2\n",
    "        \n",
    "        self.fc6 = nn.Sequential()\n",
    "        self.fc6.add_module('fc6_s1',nn.Linear(256*output_size, 1024))\n",
    "        self.fc6.add_module('relu6_s1',nn.ReLU(inplace=True))\n",
    "        self.fc6.add_module('drop6_s1',nn.Dropout(p=0.5))\n",
    "\n",
    "        self.fc7 = nn.Sequential()\n",
    "        self.fc7.add_module('fc7',nn.Linear(4*1024,4096))\n",
    "        self.fc7.add_module('relu7',nn.ReLU(inplace=True))\n",
    "        self.fc7.add_module('drop7',nn.Dropout(p=0.5))\n",
    "\n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('fc8',nn.Linear(4096, classes))\n",
    "        \n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def load(self,checkpoint):\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = torch.load(checkpoint)\n",
    "        pretrained_dict = {k: v for k, v in list(pretrained_dict.items()) if k in model_dict and 'fc8' not in k}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "        print([k for k, v in list(pretrained_dict.items())])\n",
    "\n",
    "    def save(self, checkpoint):\n",
    "        torch.save(self.state_dict(), checkpoint)\n",
    "        print(f'Model saved: {checkpoint}')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,T,C,H,W = x.size()\n",
    "        x = x.transpose(0,1)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(4):\n",
    "            z = self.conv(x[i])\n",
    "            z = self.fc6(z.view(B,-1))\n",
    "            z = z.view([B,1,-1])\n",
    "            x_list.append(z)\n",
    "\n",
    "        x = cat(x_list,1)\n",
    "        x = self.fc7(x.view(B,-1))\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def weights_init(model):\n",
    "    if type(model) in [nn.Conv2d,nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "        nn.init.constant_(model.bias.data, 0.1)\n",
    "\n",
    "class LRN(nn.Module):\n",
    "    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
    "        super(LRN, self).__init__()\n",
    "        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
    "        if ACROSS_CHANNELS:\n",
    "            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n",
    "                    stride=1,padding=(int((local_size-1.0)/2), 0, 0))\n",
    "        else:\n",
    "            self.average=nn.AvgPool2d(kernel_size=local_size,\n",
    "                    stride=1,padding=int((local_size-1.0)/2))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.ACROSS_CHANNELS:\n",
    "            div = x.pow(2).unsqueeze(1)\n",
    "            div = self.average(div).squeeze(1)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        else:\n",
    "            div = x.pow(2)\n",
    "            div = self.average(div)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        x = x.div(div)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(patch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.ones([1, 4, 1, 150, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Salk)",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
