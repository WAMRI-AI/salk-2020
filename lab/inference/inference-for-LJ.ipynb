{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.script import *\n",
    "import fastai.vision.learner as fvl\n",
    "from fastai.vision.learner import cnn_config\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.util import random_noise\n",
    "from functools import partial\n",
    "from model.metrics import *\n",
    "from data.utils import load_img\n",
    "import libtiff\n",
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "from csbdeep.utils import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = Path('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/05_hr.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/05_lr_acquired.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/05_pred_emrealworld_em_AG_D_sameas_preprint3.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/42_hr.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/42_lr_acquired.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/42_pred_emrealworld_em_AG_D_sameas_preprint3.tif')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files = sorted(list(data_pth.glob('*.tif')))\n",
    "img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/05_pred_emrealworld_em_AG_D_sameas_preprint3.tif'),\n",
       " PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/emrealworld_em_AG_D_sameas_preprint/42_pred_emrealworld_em_AG_D_sameas_preprint3.tif')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = sorted([img_files[2], img_files[5]])\n",
    "targets = sorted([img_files[0], img_files[3]])\n",
    "inputs = sorted([img_files[1], img_files[4]])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1 = PIL.Image.open(preds[0])\n",
    "targ1 = PIL.Image.open(targets[0])\n",
    "inp1 = PIL.Image.open(inputs[0])\n",
    "pred2 = PIL.Image.open(preds[1])\n",
    "targ2 = PIL.Image.open(targets[1])\n",
    "inp2 = PIL.Image.open(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1_arr = np.array(pred1)\n",
    "targ1_arr = np.array(targ1)\n",
    "inp1_arr = np.array(inp1)\n",
    "pred2_arr = np.array(pred2)\n",
    "targ2_arr = np.array(targ2)\n",
    "inp2_arr = np.array(inp2)\n",
    "targ2_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.178023273248346"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_psnr(targ1_arr, pred1_arr, data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799516770354562"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_ssim(targ1_arr, pred1_arr, data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.384507801570003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_psnr(targ2_arr, pred2_arr, data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6107373728964813"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_ssim(targ2_arr, pred2_arr, data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "def _ssim(img1, img2, window, window_size, channel, data_range=255., padding=False, size_average = True):\n",
    "    if padding:\n",
    "        padding = window_size // 2\n",
    "    mu1 = F.conv2d(img1, window, padding = int(padding), groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = int(padding), groups = channel)\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = int(padding), groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = int(padding), groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = int(padding), groups = channel) - mu1_mu2\n",
    "    C1 = (0.01*data_range)**2\n",
    "    C2 = (0.03*data_range)**2\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "def ssim(img1, img2, window_size = 11, data_range=255, padding = False, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    return _ssim(img1, img2, window, window_size, channel, data_range, padding, size_average)\n",
    "def psnr(pred, targs, data_range=255):\n",
    "    mse = F.mse_loss(pred, targs)\n",
    "    return 20 * torch.log10(data_range / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.1780, device='cuda:1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr(torch.FloatTensor(pred1_arr).cuda(), torch.FloatTensor(targ1_arr).cuda(), data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "getCudnnDataType() not supported for Int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-532c4b9557f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m ssim(torch.cuda.IntTensor(pred1_arr).reshape((1,1,500,500)), \n\u001b[1;32m      2\u001b[0m      \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg1_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m      data_range=255.)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0de0eae664bd>\u001b[0m in \u001b[0;36mssim\u001b[0;34m(img1, img2, window_size, data_range, padding, size_average)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0de0eae664bd>\u001b[0m in \u001b[0;36m_ssim\u001b[0;34m(img1, img2, window, window_size, channel, data_range, padding, size_average)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmu1_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: getCudnnDataType() not supported for Int"
     ]
    }
   ],
   "source": [
    "ssim(torch.cuda.IntTensor(pred1_arr).reshape((1,1,500,500)), \n",
    "     torch.cuda.IntTensor(targ1_arr).reshape((1,1,500,500)), \n",
    "     data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.3845, device='cuda:1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr(torch.FloatTensor(pred2_arr).cuda(), torch.FloatTensor(targ2_arr).cuda(), data_range=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6090, device='cuda:1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim(torch.FloatTensor(pred2_arr).reshape((1,1,500,500)).cuda(), \n",
    "     torch.FloatTensor(targ2_arr).reshape((1,1,500,500)).cuda(), \n",
    "     data_range=255.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Salk)",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
