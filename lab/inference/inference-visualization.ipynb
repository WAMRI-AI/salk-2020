{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from model.metrics import *\n",
    "from data.utils import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose GPU Device (kidding, we don't need one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Experiment Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mse, ssim, featureloss\n",
    "preprint, gaussian, poisson, svd, downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_name = 'featloss-toddler-greyscale'\n",
    "model_2_name = 'ssim-toddler-greyscale'\n",
    "\n",
    "data_pth = Path('/home/alaa/Dropbox/BPHO Staff/USF')  # path to dataset\n",
    "dir1 = f'EM/testing/{model_1_name}/real-world_SEM/'  # pssr images\n",
    "dir2 = f'EM/testing/{model_2_name}/real-world_SEM/'  # our images\n",
    "dir3 = f'EM/testing/LR-Bilinear/real-world_SEM/'  # bilinear images\n",
    "targ_dir = f'EM/testing/HR/real-world_SEM/'       # target images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42 files...\n"
     ]
    }
   ],
   "source": [
    "# Modify accordingly\n",
    "pth1 = data_pth/dir1\n",
    "pth2 = data_pth/dir2\n",
    "pth3 = data_pth/dir3\n",
    "targ_pth = data_pth/targ_dir\n",
    "\n",
    "dir1_files = sorted(list(pth1.glob('*.tif')))\n",
    "\n",
    "dir2_files = sorted(list(pth2.glob('*.tif')))\n",
    "\n",
    "dir3_files = sorted(list(pth3.glob('*.tif')))\n",
    "\n",
    "\n",
    "targ_files = sorted(list(targ_pth.glob('*.tif')))\n",
    "\n",
    "print('Processing '+str(len(dir1_files))+' files...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: [6.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# Set size for visualizations\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]  # Get current size\n",
    "print(\"Current size:\", fig_size)\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 30\n",
    "fig_size[1] = 24\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(img_fname1, img_fname2, targ_fname, title1=model_1_name, title2=\"Target\", title3=model_2_name):\n",
    "    pssr_im = load_img(img_fname1) # load image to tensor\n",
    "    targ_im = load_img(targ_fname)\n",
    "    our_im = load_img(img_fname2)\n",
    "    pssr_psnr = np.abs(psnr(torch.tensor(pssr_im), torch.tensor(targ_im)))\n",
    "    pssr_ssim = np.abs(ssim(torch.tensor(targ_im).unsqueeze(0), torch.tensor(pssr_im).unsqueeze(0)))\n",
    "    our_psnr = np.abs(psnr(torch.tensor(our_im), torch.tensor(targ_im)))\n",
    "    our_ssim = np.abs(ssim(torch.tensor(targ_im).unsqueeze(0), torch.tensor(our_im).unsqueeze(0)))\n",
    "    f, axarr = plt.subplots(1,3) # create visualizations\n",
    "    axarr[0].imshow(np.squeeze(pssr_im), cmap=plt.cm.gray) # visualize image tensor\n",
    "    axarr[0].set_title(title1)\n",
    "    axarr[0].set_xlabel(f\"PSNR: {pssr_psnr:.2f}, SSIM: {pssr_ssim:.2f}\")\n",
    "    axarr[1].imshow(np.squeeze(targ_im), cmap=plt.cm.gray) # visualize original image file\n",
    "    axarr[1].set_title(title2)\n",
    "    axarr[2].imshow(np.squeeze(our_im), cmap=plt.cm.gray) # visualize image tensor\n",
    "    axarr[2].set_title(title3)\n",
    "    axarr[2].set_xlabel(f\"PSNR: {our_psnr:.2f}, SSIM: {our_ssim:.2f}\")\n",
    "    plt.show() # show visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab685f2ce309414e83bcc2140f106c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=33, description='sample', max=99, min=-33), Output()), _dom_classes=('wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_sample(sample=33):\n",
    "    return visualize_sample(dir1_files[sample], dir2_files[sample], targ_files[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/alaa/Dropbox/BPHO Staff/USF/EM/testing/featureloss-resnet34-pretrained-simplecritic/real-world_SEM/realword_SEM_test_featureloss-resnet34-pretrained-simplecritic.3b_01.tif')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir2_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(pred_files, hr_files):\n",
    "    psnr_scores = {}\n",
    "    ssim_scores = {}\n",
    "    for pred_fname, targ_fname in zip(pred_files, hr_files):\n",
    "        pred_img = load_img(pred_fname)\n",
    "        targ_img = load_img(targ_fname)\n",
    "        \n",
    "        psnr_score = np.abs(psnr(torch.tensor(pred_img), torch.tensor(targ_img)))\n",
    "        psnr_scores[targ_fname] = psnr_score\n",
    "        \n",
    "        ssim_score = ssim(torch.tensor(targ_img).unsqueeze(0), torch.tensor(pred_img).unsqueeze(0))\n",
    "        ssim_scores[targ_fname] = ssim_score\n",
    "    return psnr_scores, ssim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2_psnr, dir2_ssim = evaluate_model(dir2_files, targ_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1_psnr, dir1_ssim = evaluate_model(dir1_files, targ_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.384266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIR1 PSSR PSNR MEAN\n",
    "np.mean([dir1_psnr[f] for f in dir1_psnr.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3262943"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIR1 PSSR SSIM MEAN\n",
    "np.mean([dir1_ssim[f] for f in dir1_ssim.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.687073"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE PSSR PSNR MEAN\n",
    "np.mean([dir2_psnr[f] for f in dir2_psnr.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24874298"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE PSSR SSIM MEAN\n",
    "np.mean([dir2_ssim[f] for f in dir2_ssim.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = Path('/home/alaa/Dropbox/BPHO Staff/USF')  # path to dataset\n",
    "dir1 = f'EM/testing/feat_loss_2b/real-world_SEM/'  # pssr images\n",
    "dir2 = f'EM/testing/feat_loss_imagenet/real-world_SEM/'  # our images\n",
    "dir3 = f'EM/testing/feat_loss_pssr_baseline/real-world_SEM/'  # bilinear images\n",
    "targ_dir = f'EM/testing/HR/real-world_SEM/'       # target images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42 files...\n",
      "feat_loss_pssr_baseline\n",
      "psnr: 21.097625732421875, ssim: 0.22977863252162933\n"
     ]
    }
   ],
   "source": [
    "# Modify accordingly\n",
    "pth1 = data_pth/dir1\n",
    "pth2 = data_pth/dir2\n",
    "pth3 = data_pth/dir3\n",
    "targ_pth = data_pth/targ_dir\n",
    "\n",
    "dir1_files = sorted(list(pth1.glob('*.tif')))\n",
    "\n",
    "dir2_files = sorted(list(pth2.glob('*.tif')))\n",
    "\n",
    "dir3_files = sorted(list(pth3.glob('*.tif')))\n",
    "\n",
    "\n",
    "targ_files = sorted(list(targ_pth.glob('*.tif')))\n",
    "\n",
    "print('Processing '+str(len(dir1_files))+' files...')\n",
    "\n",
    "for model, folder in zip([dir1, dir2, dir3], [dir1_files, dir2_files, dir3_files]):\n",
    "    dicts = evaluate_model(folder, targ_files)\n",
    "    scores = []\n",
    "    for dic in dicts:\n",
    "        scores.append(np.mean([dic[f] for f in dic.keys()]))\n",
    "    print(model[11:-16])\n",
    "    print(f'psnr: {scores[0]}, ssim: {scores[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Salk)",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
