{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading EM Images into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "import PIL\n",
    "import imageio\n",
    "import libtiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 67157 files...\n"
     ]
    }
   ],
   "source": [
    "# Modify accordingly\n",
    "path = Path('/data/alaa/Dropbox (BPHO)/BPHO Staff/USF/EM/')\n",
    "\n",
    "dataset_name = 'real-world_SEM'\n",
    "\n",
    "lr_name = f'training/trainsets/crappified/'\n",
    "lr_path = path/f'{lr_name}'\n",
    "lr_files = list(lr_path.glob('*.tif'))\n",
    "\n",
    "hr_name = f'training/trainsets/hr/'\n",
    "hr_path = path/f'{hr_name}'\n",
    "hr_files = list(hr_path.glob('*.tif'))\n",
    "\n",
    "print('Processing '+str(len(lr_files))+' files...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_fn):\n",
    "    \"\"\"Loads input image into matrix using filename\"\"\"\n",
    "    img = libtiff.TiffFile(img_fn)\n",
    "    img_mat = img.get_tiff_array()[0].astype(np.float32)[np.newaxis, :]\n",
    "    return img_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort filenames so that they are aligned for visualization\n",
    "lr_files = sorted(lr_files)\n",
    "hr_files = sorted(hr_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/data/alaa/Dropbox (BPHO)/BPHO Staff/USF/EM/training/trainsets/crappified/EM_train_lr_00002.tif'),\n",
       " PosixPath('/data/alaa/Dropbox (BPHO)/BPHO Staff/USF/EM/training/trainsets/hr/EM_train_hr_00002.tif'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_files[0], hr_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: [6.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# Set size for visualizations\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]  # Get current size\n",
    "print(\"Current size:\", fig_size)\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the Use of SVD as a Potential Crappification Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method computes the right singular vectors (v) and singular values 6t7of the input matrix A\n",
    "def compute_right_singular_vals(A):\n",
    "    ATA = A.T @ A\n",
    "    eigvals, eigvecs = np.linalg.eigh(ATA)\n",
    "    V = np.flip(eigvecs, 1)\n",
    "    S = np.sqrt(np.flip(eigvals))\n",
    "    return S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method computes the left singular vectors (v) of the input matrix A\n",
    "def compute_left_singular_vals(A, S, V, m, n):\n",
    "    U = np.zeros((m,m))\n",
    "    num_iters = min(m, n)\n",
    "    for j in range(num_iters):\n",
    "        U[:, j] = A @ V[:, j] / S[j]\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method computes a reconstructe image using the best rank k approximation \n",
    "def reconstruct_img(U, S, V, k):\n",
    "    img = 0\n",
    "    for j in range(k):\n",
    "        img += S[j] * np.outer(U[:, j], V[:, j])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method computes the singular value decomposition of an input matrix\n",
    "def compute_svd(img, k=20):\n",
    "    # convert image array to float\n",
    "    A = np.squeeze(img.astype(float))\n",
    "    # get image dimensions\n",
    "    m, n = A.shape\n",
    "    # compute right singular vectors and the singular values\n",
    "    S, V = compute_right_singular_vals(A)\n",
    "    # compute left singular vectors\n",
    "    U = compute_left_singular_vals(A, S, V, m, n)\n",
    "    S = np.nan_to_num(S)\n",
    "    # reconstruct input using rank k best approximation\n",
    "    compressed_img = reconstruct_img(U, S, V, k)\n",
    "    return compressed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_svd(lr_fn, hr_fn, lr_k=50, hr_k=25):\n",
    "    lr_im = load_img(lr_fn) # load image to tensor\n",
    "    hr_im = load_img(hr_fn)\n",
    "    f, axarr = plt.subplots(2,2) # create visualizations\n",
    "    axarr[0][0].imshow(np.squeeze(hr_im), cmap=plt.cm.gray) # visualize image tensor\n",
    "    axarr[0][0].set_title(\"HR\")\n",
    "    axarr[0][1].imshow(compute_svd(hr_im, k=hr_k), cmap=plt.cm.gray) # visualize image tensor\n",
    "    axarr[0][1].set_title(\"HR SVD\")\n",
    "    axarr[1][0].imshow(np.squeeze(lr_im), cmap=plt.cm.gray) # visualize original image file\n",
    "    axarr[1][0].set_title(\"LR\")\n",
    "    axarr[1][1].imshow(compute_svd(lr_im, k=lr_k), cmap=plt.cm.gray) # visualize original image file\n",
    "    axarr[1][1].set_title(\"LR SVD\")\n",
    "    plt.show() # show visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d3a727f47d4541b46bea58856dfe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='sample', max=30, min=-10), Output()), _dom_classes=('wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_sample(sample=10):\n",
    "    return visualize_svd(lr_files[sample], hr_files[sample], lr_k=50, hr_k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we Perform Image Crappification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crap:\n",
    "    \"\"\"This is Crap: the embodiment of the crappification process. \n",
    "        Parameters should consist of crapifying methods \n",
    "        e.g. SVD, gaussian blur, Neural-Network-based noise predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, crappifier, config={'default': int}):\n",
    "        \n",
    "        # your crappify method of choice\n",
    "        self.crapify = crappifier\n",
    "        # contains hyperparameters e.g. number of singular values\n",
    "        self.config = config\n",
    "        \n",
    "    def fit(self, X):\n",
    "    \"Crappify your images\"\n",
    "        return self.crapify(X, settings=self.config)\n",
    "    \n",
    "    def __del__(self):\n",
    "    \"Destroy process and reinitialize\"\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def SVD(self):\n",
    "    \"Apply Singular Value Decomposition to dataset\"\n",
    "    \n",
    "        #TODO: Linear Algebra hw_final <-- but pick random singular values!\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def gaus_blur(self):\n",
    "    \"Apply Gaussian Blur to dataset\"\n",
    "    \n",
    "    #TODO: Annette's notebook <-- but make it more random!\n",
    "    raise NotImplemented\n",
    "    \n",
    "    def s_p(self):\n",
    "    \"Apply salt & pepper noise to dataset\"\n",
    "    \n",
    "    #TODO: It's already randomized; that's good!\n",
    "    raise NotImplemented\n",
    "    \n",
    "    def model(self):\n",
    "    \"Apply predictions from another neural network\"\n",
    "    \n",
    "    #This one might be too difficult to do, but would be interesting to see\n",
    "    raise NotImplemented\n",
    "    \n",
    "    def visualize(self):\n",
    "    \"Show visual inspection of LR-HR image pairs\"\n",
    "    \n",
    "    # This has been implemented in another notebook\n",
    "    # TODO: Refactor visualization notebook \n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Salk",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
